{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "jonathan_AICAS2022.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sebastienwood/MemristorQuant/blob/main/jonathan_AICAS2022.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mcaXW6LerUwD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import code"
      ],
      "metadata": {
        "id": "bVJ-ZCZlrWca"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "M8NUEYPGrMTT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f126ec7-5298-473d-c64a-e487bcd9ff33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "fatal: destination path 'pytorch-classification' already exists and is not an empty directory.\n",
            "/content/pytorch-classification\n"
          ]
        }
      ],
      "source": [
        "%cd /content\n",
        "!git clone --recursive https://github.com/bearpaw/pytorch-classification.git\n",
        "\n",
        "%cd /content/pytorch-classification/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''Adapted from VGG for CIFAR10. FC layers are removed.\n",
        "(c) YANG, Wei \n",
        "'''\n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "\n",
        "class VGG(nn.Module):\n",
        "\n",
        "    def __init__(self, features, num_classes=1000):\n",
        "        super(VGG, self).__init__()\n",
        "        self.features = features\n",
        "        self.classifier = nn.Linear(512, num_classes, bias=False)\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "    #forward pass but with only fully connected layers\n",
        "    def forward_fc(self, x):\n",
        "        channels = 64 #TODO: this is architecture specific\n",
        "        width = 32 #TODO: this is architecture specific\n",
        "        \n",
        "        for layer in self.features:\n",
        "            if isinstance(layer, nn.Linear):\n",
        "                x = torch.nn.functional.pad(x, (1, 1, 1, 1)) #padding\n",
        "                x = x.view(x.size(0), -1)\n",
        "                x = layer(x)\n",
        "                x = x.reshape(x.shape[0], min(512, int(channels)), int(width), int(width))\n",
        "                channels*=2 #TODO: this is architecture specific\n",
        "                width/=2 #TODO: this is architecture specific\n",
        "            else:\n",
        "                x = layer(x)\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "                if m.bias is not None:\n",
        "                    m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                n = m.weight.size(1)\n",
        "                m.weight.data.normal_(0, 0.01)\n",
        "                if m.bias is not None:\n",
        "                    m.bias.data.zero_()\n",
        "\n",
        "\n",
        "def make_layers(cfg, batch_norm=False):\n",
        "    layers = []\n",
        "    in_channels = 3\n",
        "    for v in cfg:\n",
        "        if v == 'A':\n",
        "            layers += [nn.AvgPool2d(kernel_size=2, stride=2)]\n",
        "        else:\n",
        "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1, bias=False)\n",
        "            if batch_norm:\n",
        "                layers += [conv2d, nn.BatchNorm2d(v), nn.Softplus()]\n",
        "            else:\n",
        "                layers += [conv2d, nn.Softplus()]\n",
        "            in_channels = v\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "cfg = {\n",
        "    'small_vgg': [64, 'A', 128, 'A', 256, 'A', 512, 'A', 512, 'A'],\n",
        "    'really_small_vgg': [16, 'A', 32, 'A', 64, 'A', 128, 'A', 128, 'A'],\n",
        "}\n",
        "\n",
        "\n",
        "def small_vgg(**kwargs):\n",
        "    \"\"\"Small VGG model\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = VGG(make_layers(cfg['small_vgg'], batch_norm=False), **kwargs)\n",
        "    return model"
      ],
      "metadata": {
        "id": "HwCsOCSF_Crn"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from https://github.com/pytorch/pytorch/issues/26781#issuecomment-821054668\n",
        "def convmatrix2d(kernel, image_shape, padding=None):\n",
        "    # kernel: (out_channels, in_channels, kernel_height, kernel_width, ...)\n",
        "    # image: (in_channels, image_height, image_width, ...)\n",
        "\n",
        "    if padding:\n",
        "        assert padding[0] == padding[1]\n",
        "        padding = padding[0]\n",
        "        old_shape = image_shape\n",
        "        pads = (padding, padding, padding, padding)\n",
        "        image_shape = (image_shape[0], image_shape[1] + padding*2, image_shape[2]\n",
        "                       + padding*2)\n",
        "    else:\n",
        "        image_shape = tuple(image_shape)\n",
        "\n",
        "    assert image_shape[0] == kernel.shape[1]\n",
        "    assert len(image_shape[1:]) == len(kernel.shape[2:])\n",
        "    result_dims = torch.tensor(image_shape[1:]) - torch.tensor(kernel.shape[2:]) + 1\n",
        "    m = torch.zeros((\n",
        "        kernel.shape[0], \n",
        "        *result_dims, \n",
        "        *image_shape\n",
        "    ))\n",
        "    for i in range(m.shape[1]):\n",
        "        for j in range(m.shape[2]):\n",
        "            m[:,i,j,:,i:i+kernel.shape[2],j:j+kernel.shape[3]] = kernel\n",
        "    return m.flatten(0, len(kernel.shape[2:])).flatten(1)\n",
        "\n",
        "    # Handle zero padding. Effectively, the zeros from padding do not\n",
        "    # contribute to convolution output as the product at those elements is zero.\n",
        "    # Hence the columns of the conv mat that are at the indices where the\n",
        "    # padded flattened image would have zeros can be ignored. The number of\n",
        "    # rows on the other hand must not be altered (with padding the output must\n",
        "    # be larger than without). So..\n",
        "\n",
        "    # We'll handle this the easy way and create a mask that accomplishes the\n",
        "    # indexing\n",
        "    if padding:\n",
        "        mask = torch.nn.functional.pad(torch.ones(old_shape), pads).flatten()\n",
        "        mask = mask.bool()\n",
        "        m = m[:, mask]\n",
        "\n",
        "    return m"
      ],
      "metadata": {
        "id": "sdG_639d7aPl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/pytorch-classification/ \n",
        "'''\n",
        "Training script for CIFAR-10/100\n",
        "Copyright (c) Wei YANG, 2017\n",
        "'''\n",
        "from __future__ import print_function\n",
        "\n",
        "import argparse\n",
        "import os\n",
        "import shutil\n",
        "import time\n",
        "import random\n",
        "import sys\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import importlib\n",
        "import models.cifar as models\n",
        "from torchsummary import summary\n",
        "\n",
        "from utils import Bar, Logger, AverageMeter, mkdir_p, savefig\n",
        "\n",
        "arch = \"small_vgg\"\n",
        "checkpoint = \"/content/pytorch-classification/checkpoints/cifar10/\" + arch\n",
        "\n",
        "resume = \"/content/pytorch-classification/checkpoints/cifar10/\" + arch + \"/model_best.pth.tar\"\n",
        "#resume = False\n",
        "evaluate = True\n",
        "conv_to_fc = True\n",
        "\n",
        "dataset = \"cifar10\"\n",
        "start_epoch = 0\n",
        "# Training settings (from https://github.com/bearpaw/pytorch-classification/blob/24f1c456f48c78133088c4eefd182ca9e6199b03/TRAINING.md)\n",
        "lr = 0.1\n",
        "epochs = 164\n",
        "decrease_lr_at_epochs = [81, 122]\n",
        "\n",
        "prototyping = True\n",
        "if prototyping:\n",
        "  epochs = 1\n",
        "  resume = False\n",
        "  evaluate = False\n",
        "  conv_to_fc = True\n",
        "\n",
        "# Use CUDA\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
        "use_cuda = torch.cuda.is_available()\n",
        "print(f'use_cuda={use_cuda}')\n",
        "test_batch = 100\n",
        "train_batch = 128\n",
        "workers = 2\n",
        "\n",
        "# Random seed\n",
        "manualSeed = 2\n",
        "random.seed(manualSeed)\n",
        "torch.manual_seed(manualSeed)\n",
        "if use_cuda:\n",
        "    torch.cuda.manual_seed_all(manualSeed)\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "drop = 0\n",
        "\n",
        "best_acc = 0  # best test accuracy\n",
        "\n",
        "if not os.path.isdir(checkpoint):\n",
        "    mkdir_p(checkpoint)\n",
        "  \n",
        "\n",
        "# Data\n",
        "print('==> Preparing dataset %s' % dataset)\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "if dataset == 'cifar10':\n",
        "    dataloader = datasets.CIFAR10\n",
        "    num_classes = 10\n",
        "    input_shape = (3, 32, 32)\n",
        "else:\n",
        "    dataloader = datasets.CIFAR100\n",
        "    num_classes = 100\n",
        "    input_shape = (3, 32, 32)\n",
        "\n",
        "\n",
        "trainset = dataloader(root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = data.DataLoader(trainset, batch_size=train_batch, shuffle=True, num_workers=workers)\n",
        "\n",
        "testset = dataloader(root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = data.DataLoader(testset, batch_size=test_batch, shuffle=False, num_workers=workers)\n",
        "\n",
        "# Model\n",
        "print(\"==> creating model '{}'\".format(arch))\n",
        "if arch == \"small_vgg\":\n",
        "    model = small_vgg(num_classes=num_classes)\n",
        "\n",
        "if use_cuda:\n",
        "    model = torch.nn.DataParallel(model).cuda()\n",
        "print(model)\n",
        "\n",
        "cudnn.benchmark = True\n",
        "print('    Total params: %.2fM' % (sum(p.numel() for p in model.parameters())/1000000.0))\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "# Resume\n",
        "title = 'cifar-10-' + arch\n",
        "if resume:\n",
        "    # Load checkpoint.\n",
        "    print('==> Resuming from checkpoint..')\n",
        "    assert os.path.isfile(resume), 'Error: no checkpoint directory found!'\n",
        "    checkpoint = os.path.dirname(resume)\n",
        "    if use_cuda:\n",
        "        checkpoint = torch.load(resume)\n",
        "        model.load_state_dict(checkpoint['state_dict'])\n",
        "    else:\n",
        "        checkpoint = torch.load(resume, map_location=torch.device('cpu'))\n",
        "        rename_state_dict = checkpoint['state_dict'].copy()\n",
        "        for key in checkpoint['state_dict'].keys():\n",
        "            if \"module.\" in key:\n",
        "                rename_state_dict[key.replace('module.', '')] = checkpoint['state_dict'][key]\n",
        "                rename_state_dict.pop(key)\n",
        "        checkpoint['state_dict'] = rename_state_dict\n",
        "        model.load_state_dict(checkpoint['state_dict'])\n",
        "\n",
        "    best_acc = checkpoint['best_acc']\n",
        "    start_epoch = checkpoint['epoch']\n",
        "else:\n",
        "    logger = Logger(os.path.join(checkpoint, 'log.txt'), title=title)\n",
        "    logger.set_names(['Train Loss', 'Valid Loss', 'Train Acc.', 'Valid Acc.'])\n",
        "\n",
        "if conv_to_fc:\n",
        "\n",
        "    print(\"==> converting Conv2d to Linear\")\n",
        "    print(summary(model, input_shape))\n",
        "\n",
        "    VGG.forward = VGG.forward_fc\n",
        "\n",
        "    if use_cuda:\n",
        "        layers = model.module.features.children()\n",
        "        x = torch.zeros(input_shape).cuda()\n",
        "    else:\n",
        "        layers = model.features.children()\n",
        "        x = torch.zeros(input_shape)\n",
        "    x = x[None, :, :, :]\n",
        "\n",
        "    current_input_shape = input_shape\n",
        "    for ind_layer, layer in enumerate(layers):\n",
        "        if isinstance(layer, nn.Conv2d):\n",
        "            kernel = layer.weight\n",
        "            conv_matrix = convmatrix2d(kernel, current_input_shape, layer.padding)\n",
        "\n",
        "            if use_cuda:\n",
        "                model.module.features[ind_layer] = nn.Linear(conv_matrix.shape[1], conv_matrix.shape[0], bias=False, device=\"cuda:0\")\n",
        "                model.module.features[ind_layer].weight.data = conv_matrix.cuda()\n",
        "            else:\n",
        "                model.features[ind_layer] = nn.Linear(conv_matrix.shape[1], conv_matrix.shape[0], bias=False)\n",
        "                model.features[ind_layer].weight.data = conv_matrix\n",
        "        x = layer(x)\n",
        "        current_input_shape = tuple(x.shape[1:])\n",
        "    \n",
        "    print(\"==> converted Conv2d to Linear\")            \n",
        "    print(summary(model, input_shape))\n",
        "\n",
        "    #TODO: iterate though the layers and update the weights here\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
        "    maxk = max(topk)\n",
        "    batch_size = target.size(0)\n",
        "\n",
        "    _, pred = output.topk(maxk, 1, True, True)\n",
        "    pred = pred.t()\n",
        "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "    res = []\n",
        "    for k in topk:\n",
        "        correct_k = correct[:k].reshape(-1).float().sum(0)\n",
        "        res.append(correct_k.mul_(100.0 / batch_size))\n",
        "    return res\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(testloader, model, criterion, epoch, use_cuda):\n",
        "    global best_acc\n",
        "\n",
        "    batch_time = AverageMeter()\n",
        "    data_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "    top5 = AverageMeter()\n",
        "\n",
        "    # switch to evaluate mode\n",
        "    model.eval()\n",
        "\n",
        "    end = time.time()\n",
        "    bar = Bar('Processing', max=len(testloader))\n",
        "\n",
        "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "        # measure data loading time\n",
        "        data_time.update(time.time() - end)\n",
        "\n",
        "        if use_cuda:\n",
        "            inputs, targets = inputs.cuda(), targets.cuda()\n",
        "        #inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
        "        # deprecated \n",
        "\n",
        "        # compute output\n",
        "        if use_cuda:\n",
        "          with torch.cuda.amp.autocast():\n",
        "            outputs = model(inputs)\n",
        "        else:\n",
        "          outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        if use_cuda:\n",
        "          scaler.scale(loss)\n",
        "        # measure accuracy and record loss\n",
        "        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n",
        " \n",
        "        losses.update(loss.item(), inputs.size(0))\n",
        "        top1.update(prec1.item(), inputs.size(0))\n",
        "        top5.update(prec5.item(), inputs.size(0))\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        # plot progress\n",
        "        bar.suffix  = '({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | Loss: {loss:.4f} | top1: {top1: .4f} | top5: {top5: .4f}'.format(\n",
        "                    batch=batch_idx + 1,\n",
        "                    size=len(testloader),\n",
        "                    data=data_time.avg,\n",
        "                    bt=batch_time.avg,\n",
        "                    total=bar.elapsed_td,\n",
        "                    eta=bar.eta_td,\n",
        "                    loss=losses.avg,\n",
        "                    top1=top1.avg,\n",
        "                    top5=top5.avg,\n",
        "                    )\n",
        "        bar.next()\n",
        "    bar.finish()\n",
        "    return (losses.avg, top1.avg)\n",
        "\n",
        "if evaluate:\n",
        "    print('\\nEvaluation only')\n",
        "    test_loss, test_acc = test(testloader, model, criterion, start_epoch, use_cuda)\n",
        "    print(' Test Loss:  %.8f, Test Acc:  %.2f' % (test_loss, test_acc))\n",
        "    sys.exit()\n",
        "\n",
        "def train(trainloader, model, criterion, optimizer, epoch, use_cuda):\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "\n",
        "    batch_time = AverageMeter()\n",
        "    data_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "    top5 = AverageMeter()\n",
        "    end = time.time()\n",
        "\n",
        "    bar = Bar('Processing', max=len(trainloader))\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        # measure data loading time\n",
        "        data_time.update(time.time() - end)\n",
        "\n",
        "        if use_cuda:\n",
        "            inputs, targets = inputs.cuda(), targets.cuda()\n",
        "        #inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
        "        # deprecated \n",
        "\n",
        "        # compute output\n",
        "        if use_cuda:\n",
        "          with torch.cuda.amp.autocast():\n",
        "            outputs = model(inputs)\n",
        "        else:\n",
        "          outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        # measure accuracy and record loss\n",
        "        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n",
        "        losses.update(loss.data.item(), inputs.size(0))\n",
        "        top1.update(prec1.item(), inputs.size(0))\n",
        "        top5.update(prec5.item(), inputs.size(0))\n",
        "\n",
        "        # compute gradient and do SGD step\n",
        "        optimizer.zero_grad()\n",
        "        if use_cuda:\n",
        "          scaler.scale(loss).backward()\n",
        "          scaler.step(optimizer)\n",
        "          scaler.update()\n",
        "        else:\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        # plot progress\n",
        "        bar.suffix  = '({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | Loss: {loss:.4f} | top1: {top1: .4f} | top5: {top5: .4f}'.format(\n",
        "                    batch=batch_idx + 1,\n",
        "                    size=len(trainloader),\n",
        "                    data=data_time.avg,\n",
        "                    bt=batch_time.avg,\n",
        "                    total=bar.elapsed_td,\n",
        "                    eta=bar.eta_td,\n",
        "                    loss=losses.avg,\n",
        "                    top1=top1.avg,\n",
        "                    top5=top5.avg,\n",
        "                    )\n",
        "        bar.next()\n",
        "    bar.finish()\n",
        "    return (losses.avg, top1.avg)\n",
        "\n",
        "def save_checkpoint(state, is_best, checkpoint='checkpoint', filename='checkpoint.pth.tar'):\n",
        "    filepath = os.path.join(checkpoint, filename)\n",
        "    torch.save(state, filepath)\n",
        "    if is_best:\n",
        "        shutil.copyfile(filepath, os.path.join(checkpoint, 'model_best.pth.tar'))\n",
        "\n",
        "def adjust_learning_rate(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        print(\"\\nOld learning rate: \", param_group['lr'])\n",
        "        param_group['lr'] *= 0.1\n",
        "        print(\"\\nNew learning rate: \", param_group['lr'])\n",
        "\n",
        "# Train and val\n",
        "if not conv_to_fc:\n",
        "  for epoch in range(start_epoch, epochs):\n",
        "      if epoch in decrease_lr_at_epochs:\n",
        "          adjust_learning_rate(optimizer)\n",
        "\n",
        "      print('\\nEpoch: [%d | %d]' % (epoch + 1, epochs))\n",
        "\n",
        "      train_loss, train_acc = train(trainloader, model, criterion, optimizer, epoch, use_cuda)\n",
        "      test_loss, test_acc = test(testloader, model, criterion, epoch, use_cuda)\n",
        "\n",
        "      print(' train acc: %d - test acc: %d' % (train_acc, test_acc))\n",
        "\n",
        "      # append logger file\n",
        "      logger.append([train_loss, test_loss, train_acc, test_acc])\n",
        "      # save model\n",
        "      is_best = test_acc > best_acc\n",
        "      best_acc = max(test_acc, best_acc)\n",
        "      save_checkpoint({\n",
        "              'epoch': epoch + 1,\n",
        "              'state_dict': model.state_dict(),\n",
        "              'acc': test_acc,\n",
        "              'best_acc': best_acc,\n",
        "              'optimizer' : optimizer.state_dict(),\n",
        "          }, is_best, checkpoint=checkpoint)\n",
        "\n",
        "  logger.close()\n",
        "  logger.plot()\n",
        "  savefig(os.path.join(checkpoint, 'log.eps'))\n",
        "\n",
        "  print('Best acc:')\n",
        "  print(best_acc)\n",
        "else:\n",
        "  test_loss, test_acc = test(testloader, model, criterion, 0, use_cuda)\n",
        "  print('Acc:')\n",
        "  print(test_acc)\n",
        "\n"
      ],
      "metadata": {
        "id": "QnprKpCFAJuV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5315628-6ead-4c3f-ac1a-152d3e9f3b9d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/pytorch-classification\n",
            "use_cuda=True\n",
            "==> Preparing dataset cifar10\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "==> creating model 'small_vgg'\n",
            "DataParallel(\n",
            "  (module): VGG(\n",
            "    (features): Sequential(\n",
            "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): Softplus(beta=1, threshold=20)\n",
            "      (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "      (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (4): Softplus(beta=1, threshold=20)\n",
            "      (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "      (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (7): Softplus(beta=1, threshold=20)\n",
            "      (8): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "      (9): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (10): Softplus(beta=1, threshold=20)\n",
            "      (11): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "      (12): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (13): Softplus(beta=1, threshold=20)\n",
            "      (14): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "    )\n",
            "    (classifier): Linear(in_features=512, out_features=10, bias=False)\n",
            "  )\n",
            ")\n",
            "    Total params: 3.91M\n",
            "==> converting Conv2d to Linear\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
            "          Softplus-2           [-1, 64, 32, 32]               0\n",
            "         AvgPool2d-3           [-1, 64, 16, 16]               0\n",
            "            Conv2d-4          [-1, 128, 16, 16]          73,728\n",
            "          Softplus-5          [-1, 128, 16, 16]               0\n",
            "         AvgPool2d-6            [-1, 128, 8, 8]               0\n",
            "            Conv2d-7            [-1, 256, 8, 8]         294,912\n",
            "          Softplus-8            [-1, 256, 8, 8]               0\n",
            "         AvgPool2d-9            [-1, 256, 4, 4]               0\n",
            "           Conv2d-10            [-1, 512, 4, 4]       1,179,648\n",
            "         Softplus-11            [-1, 512, 4, 4]               0\n",
            "        AvgPool2d-12            [-1, 512, 2, 2]               0\n",
            "           Conv2d-13            [-1, 512, 2, 2]       2,359,296\n",
            "         Softplus-14            [-1, 512, 2, 2]               0\n",
            "        AvgPool2d-15            [-1, 512, 1, 1]               0\n",
            "           Linear-16                   [-1, 10]           5,120\n",
            "              VGG-17                   [-1, 10]               0\n",
            "================================================================\n",
            "Total params: 3,914,432\n",
            "Trainable params: 3,914,432\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.14\n",
            "Params size (MB): 14.93\n",
            "Estimated Total Size (MB): 17.09\n",
            "----------------------------------------------------------------\n",
            "None\n",
            "==> converted Conv2d to Linear\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                [-1, 65536]     227,278,848\n",
            "          Softplus-2           [-1, 64, 32, 32]               0\n",
            "         AvgPool2d-3           [-1, 64, 16, 16]               0\n",
            "            Linear-4                [-1, 32768]     679,477,248\n",
            "          Softplus-5          [-1, 128, 16, 16]               0\n",
            "         AvgPool2d-6            [-1, 128, 8, 8]               0\n",
            "            Linear-7                [-1, 16384]     209,715,200\n",
            "          Softplus-8            [-1, 256, 8, 8]               0\n",
            "         AvgPool2d-9            [-1, 256, 4, 4]               0\n",
            "           Linear-10                 [-1, 8192]      75,497,472\n",
            "         Softplus-11            [-1, 512, 4, 4]               0\n",
            "        AvgPool2d-12            [-1, 512, 2, 2]               0\n",
            "           Linear-13                 [-1, 2048]      16,777,216\n",
            "         Softplus-14            [-1, 512, 2, 2]               0\n",
            "        AvgPool2d-15            [-1, 512, 1, 1]               0\n",
            "           Linear-16                   [-1, 10]           5,120\n",
            "              VGG-17                   [-1, 10]               0\n",
            "================================================================\n",
            "Total params: 1,208,751,104\n",
            "Trainable params: 1,208,751,104\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.14\n",
            "Params size (MB): 4611.02\n",
            "Estimated Total Size (MB): 4613.18\n",
            "----------------------------------------------------------------\n",
            "None\n",
            "Acc:\n",
            "10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Iterator\n",
        "def net_param_iterator(model: nn.Module) -> Iterator:\n",
        "  ignored = []\n",
        "  for name, module in model.named_modules():\n",
        "    if type(module) in [nn.Conv2d, nn.BatchNorm2d, nn.ReLU, nn.Linear]:\n",
        "      #TODO preparse params ?\n",
        "      yield module\n",
        "    else:\n",
        "      ignored.append(type(module))\n",
        "  print(set(ignored))\n",
        "\n",
        "\n",
        "class MemristorQuant(object):\n",
        "  def __init__(self, model: nn.Module, types_handled = [nn.Linear], N: int = 100, wmax_mode='all', Gmax=0.1, std_noise:float=1.) -> None:\n",
        "      super().__init__()\n",
        "      self.model = model\n",
        "      self.saved_params = []\n",
        "      self.actual_params = [] \n",
        "      self.intermediate_params = {}\n",
        "      for m in model.modules():\n",
        "        if type(m) in types_handled:\n",
        "          self.saved_params.append(m.weight.data.clone().cpu())\n",
        "          self.actual_params.append(m.weight)\n",
        "      self.quanted = False\n",
        "      self.N = N\n",
        "      self.wmax_mode = wmax_mode\n",
        "      self.Gmax = Gmax\n",
        "      self.std_noise = std_noise\n",
        "      print(f\"Initialized memquant with {len(self.saved_params)} parameters quantified\")\n",
        "\n",
        "  def __call__(self, input):\n",
        "    return self.forward(input)\n",
        "\n",
        "  def forward(self, input):\n",
        "    # WARNING: do not use this forward for learning, it does 2 forward with 1 batch\n",
        "    res_reliable = self.model(input).detach()\n",
        "    if not self.quanted:\n",
        "      self.quant()\n",
        "    self.renoise()\n",
        "    res = self.model(input)\n",
        "    self.unquant()\n",
        "    self.MSE = torch.mean(torch.square(res - res_reliable))\n",
        "    return res, res_reliable\n",
        "\n",
        "  @staticmethod\n",
        "  def memory_usage(tensor):\n",
        "    '''Return memory usage in MB'''\n",
        "    return tensor.element_size() * tensor.nelement() / 1e6\n",
        "\n",
        "  def memory_info(self):\n",
        "    for i in range(len(self.saved_params)):\n",
        "      print(f'Tensor {i} of shape {self.saved_params[i].shape}')\n",
        "      print(f'Saved version dtype {self.saved_params[i].dtype} on {self.saved_params[i].device} (taking {self.memory_usage(self.saved_params[i])}) MB')\n",
        "      print(f'Current version dtype {self.actual_params[i].dtype} on {self.actual_params[i].device} (taking {self.memory_usage(self.actual_params[i])}) MB')\n",
        "\n",
        "  def quant(self):\n",
        "    if self.quanted:\n",
        "      self.unquant()\n",
        "    for i in range(len(self.saved_params)):\n",
        "      true_value = self.actual_params[i].data\n",
        "      self.saved_params[i].copy_(true_value.clone().cpu())\n",
        "      self._quantize(true_value)\n",
        "      self.intermediate_params[i] = true_value.clone().cpu()\n",
        "      self.actual_params[i].data.copy_(true_value)\n",
        "    self.quanted = True\n",
        "\n",
        "  def renoise(self):\n",
        "    for i, inter in self.intermediate_params.items():\n",
        "      self.actual_params[i].data.copy_(self.intermediate_params[i])\n",
        "      self.actual_params[i].data += torch.normal(mean=0., std=self.std_noise, size=self.actual_params[i].shape, device=self.actual_params[i].device)\n",
        "\n",
        "  def unquant(self):\n",
        "    if self.quanted:\n",
        "      for i in range(len(self.saved_params)):\n",
        "        self.actual_params[i].data.copy_(self.saved_params[i].to(self.actual_params[i].data))\n",
        "    self.quanted = False\n",
        "\n",
        "  @torch.no_grad()\n",
        "  def _quantize(self, tensor) -> None:\n",
        "    c = self.Gmax / self.Wmax(tensor)\n",
        "    delta = self.Gmax / self.N\n",
        "    tensor *= c\n",
        "    tensor /= delta\n",
        "    torch.floor_(tensor)\n",
        "    tensor += 0.5\n",
        "    tensor *= delta\n",
        "\n",
        "  @torch.no_grad()\n",
        "  def Wmax(self, tensor):\n",
        "    assert len(tensor.shape) == 2, 'Only works for 2d tensors !'\n",
        "    if self.wmax_mode == 'all':\n",
        "      return max([torch.max(torch.abs(t)) for t in self.saved_params])\n",
        "    elif self.wmax_mode == 'layerwise':\n",
        "      return torch.max(torch.abs(tensor))\n",
        "    elif self.wmax_mode == 'columnwise':\n",
        "      return torch.max(torch.abs(tensor), dim=0)\n",
        "\n",
        "# Ex usage\n",
        "quanter = MemristorQuant(model)\n",
        "# To quant\n",
        "quanter.quant()\n",
        "# To noise\n",
        "quanter.renoise()\n",
        "# To unquant\n",
        "quanter.unquant()\n",
        "\n",
        "quanter.memory_info()\n",
        "\n",
        "for i in net_param_iterator(model):\n",
        "  print(i)"
      ],
      "metadata": {
        "id": "DbOm4m4h4dHU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "695a33e9-61e9-4f88-991e-d4c150db7feb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialized memquant with 6 parameters quantified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch, _ = next(iter(testloader))\n",
        "print(batch.shape)"
      ],
      "metadata": {
        "id": "BvvPDyc0zwEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "model(batch)"
      ],
      "metadata": {
        "id": "Of3U12ZCoLnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "quanter.quant()\n",
        "model(batch)\n",
        "quanter.unquant()"
      ],
      "metadata": {
        "id": "cJPWFqYYzsFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "quanter.quant()"
      ],
      "metadata": {
        "id": "6nJmqWkBKhOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "quanter.renoise()"
      ],
      "metadata": {
        "id": "QejkRqJZKqPX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}